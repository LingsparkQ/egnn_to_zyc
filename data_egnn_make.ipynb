{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R', 'N', 'Z', 'id', 'A', 'B', 'C', 'mu', 'alpha', 'homo', 'lumo', 'gap', 'r2', 'zpve', 'U0', 'U', 'H', 'G', 'Cv', 'meta']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130829/130829 [02:41<00:00, 812.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130830\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import os.path as osp\n",
    "from qm9 import utils as qm9_utils\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "names = locals()\n",
    "# dir = \"/work/01/gq54/p23002/guyuhan/wisteria_guyuhan/data_preprocess/805_Alchemy9_for_schnet.npz\"\n",
    "dir = \"/work/01/gq54/p23002/guyuhan/wisteria_guyuhan/dimenet_used/data/qm9_eV.npz\"\n",
    "data=np.load(dir)\n",
    "print(data.files)\n",
    "prop = ['mu', 'alpha', 'homo', 'lumo', 'gap', 'r2',\n",
    "        'zpve', 'U0', 'U','H', 'G', 'Cv' ]\n",
    "split = [data['N'][0]]\n",
    "for i in tqdm(range(len(data['N'])-2)):\n",
    "        split.append(split[-1] + data['N'][i + 1])\n",
    "print(len(split))\n",
    "num_atoms_split = data['N']\n",
    "max = num_atoms_split.max()\n",
    "charges_split = np.split(data['Z'],split)\n",
    "charge_scale = data['Z'].max()\n",
    "positions_split = np.split(data['R'],split)\n",
    "index_split = data['id']\n",
    "for _ in prop:\n",
    "        names[_ + '_split'] = data[_]\n",
    "\n",
    "dict_keys1 =  ['index','num_atoms', \n",
    "        'mu', 'alpha', 'homo', 'lumo', \n",
    "        'gap', 'r2', 'zpve', 'U0', \n",
    "        'U', 'H', 'G', 'Cv',]\n",
    "dict_keys2 = ['charges', 'positions',]\n",
    "\n",
    "dict_keys3 = ['one_hot', 'atom_mask', 'edge_mask']\n",
    "\n",
    "all_species = torch.tensor(data['Z']).unique(sorted=True)\n",
    "if all_species[0] == 0:\n",
    "        all_species = all_species[1:]\n",
    "included_species = all_species\n",
    "included_species.shape\n",
    "n = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n):\n",
    "    dict_i = {}\n",
    "    # dict_i['charges'] = torch.tensor(_)\n",
    "    _ = np.pad(charges_split[i],((0), (max - charges_split[i].size)),'constant')\n",
    "    dict_i['charges'] = torch.tensor(_)\n",
    "    if i == 0:\n",
    "        all_charges = dict_i['charges'].unsqueeze(0)\n",
    "    else:\n",
    "        all_charges = torch.cat((all_charges,dict_i['charges'].unsqueeze(0)),0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 29, 5])\n"
     ]
    }
   ],
   "source": [
    "all_one_hot = all_charges.unsqueeze(-1) == included_species.unsqueeze(0).unsqueeze(0)\n",
    "print(all_one_hot.shape)\n",
    "dataset_alchemy = []\n",
    "\n",
    "for i in range(n):\n",
    "    dict_i = {}\n",
    "    for _ in dict_keys1:\n",
    "        dict_i[_] = torch.tensor(names[_ + '_split'][i])\n",
    "    _ = np.pad(charges_split[i],((0), (max - charges_split[i].size)),'constant')\n",
    "    dict_i['charges'] = torch.tensor(_)\n",
    "    if i == 0:\n",
    "        all_charges = dict_i['charges'].unsqueeze(0)\n",
    "    else:\n",
    "        all_charges = torch.cat((all_charges,dict_i['charges'].unsqueeze(0)),0)\n",
    "    _ = np.pad(positions_split[i],((0,max - positions_split[i].shape[0]), (0,0)),'constant')\n",
    "    dict_i['positions'] = torch.tensor(_)\n",
    "    # dict_i['one_hot'] = dict_i['charges'].unsqueeze(-1) == included_species.unsqueeze(0).unsqueeze(0)\n",
    "    dict_i['one_hot'] = all_one_hot[i]\n",
    "    dataset_alchemy.append(dict_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class al_dataset(Dataset):\n",
    "    def  __init__(self,name):\n",
    "        self.set = name\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(dataset_alchemy)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.set[idx]\n",
    "\n",
    "al9_set = al_dataset(dataset_alchemy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qm9.data.collate import collate_fn\n",
    "dataloaders = {'altest': DataLoader(al9_set,\n",
    "                                     batch_size=96,\n",
    "                                     shuffle=False if (split == 'train') else False,\n",
    "                                     num_workers=2,\n",
    "                                     collate_fn=collate_fn)\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qm9.models import EGNN\n",
    "best_model = torch.load('/work/01/gq54/p23002/egnn_homo/exp_1_homo/best_model',map_location='cpu')\n",
    "device = 'cpu'\n",
    "dtype = torch.float32\n",
    "model = EGNN(in_node_nf=15, in_edge_nf=0, hidden_nf=128, device=device, n_layers=7, coords_weight=1.0,\n",
    "             attention=1, node_attr=0)\n",
    "model.load_state_dict(best_model['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'altest'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_402629/338904022.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# dataloaders, charge_scale = dataset.retrieve_dataloaders(96,2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'altest'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'positions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'altest'"
     ]
    }
   ],
   "source": [
    "pred_all = [] \n",
    "from qm9 import dataset\n",
    "\n",
    "# dataloaders, charge_scale = dataset.retrieve_dataloaders(96,2)\n",
    "\n",
    "for i, data in enumerate(dataloaders['altest']):\n",
    "        model.eval()\n",
    "        batch_size, n_nodes, _ = data['positions'].size()\n",
    "        atom_positions = data['positions'].view(batch_size * n_nodes, -1).to(device, dtype)\n",
    "        atom_mask = data['atom_mask'].view(batch_size * n_nodes, -1).to(device, dtype)\n",
    "        edge_mask = data['edge_mask'].to(device, dtype)\n",
    "        one_hot = data['one_hot'].to(device, dtype)\n",
    "        charges = data['charges'].to(device, dtype)\n",
    "        nodes = qm9_utils.preprocess_input(one_hot, charges, 2, charge_scale, device)\n",
    "        nodes = nodes.view(batch_size * n_nodes, -1)\n",
    "        # nodes = torch.cat([one_hot, charges], dim=1)\n",
    "        edges = qm9_utils.get_adj_matrix(n_nodes, batch_size, device)\n",
    "        # label = data[args.property].to(device, dtype)\n",
    "        pred = model(h0=nodes, x=atom_positions, edges=edges, edge_attr=None, node_mask=atom_mask, edge_mask=edge_mask,\n",
    "                     n_nodes=n_nodes)\n",
    "        break\n",
    "        # pred_all.append(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"/work/01/gq54/p23002/guyuhan/wisteria_guyuhan/data_preprocess/805_Alchemy9_for_schnet.npz\"\n",
    "# dir = \"/work/01/gq54/p23002/guyuhan/wisteria_guyuhan/dimenet_used/data/qm9_eV.npz\"\n",
    "data=np.load(dir)\n",
    "a = torch.tensor(data['lumo'][0:96])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02754731423664206"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model['best_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "homo = np.array(data['homo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.99636051],\n",
       "       [0.99636051, 1.        ]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(pred,homo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets type: <class 'dict'>\n",
      "datasets train: <class 'qm9.data.dataset.ProcessedDataset'>\n",
      "data type in datasets train: <class 'dict'>\n",
      "dict_keys(['num_atoms', 'charges', 'positions', 'index', 'A', 'B', 'C', 'mu', 'alpha', 'homo', 'lumo', 'gap', 'r2', 'zpve', 'U0', 'U', 'H', 'G', 'Cv', 'omega1', 'zpve_thermo', 'U0_thermo', 'U_thermo', 'H_thermo', 'G_thermo', 'Cv_thermo', 'one_hot'])\n",
      "num_atoms torch.Size([])\n",
      "charges torch.Size([29])\n",
      "positions torch.Size([29, 3])\n",
      "index torch.Size([])\n",
      "A torch.Size([])\n",
      "B torch.Size([])\n",
      "C torch.Size([])\n",
      "mu torch.Size([])\n",
      "alpha torch.Size([])\n",
      "homo torch.Size([])\n",
      "lumo torch.Size([])\n",
      "gap torch.Size([])\n",
      "r2 torch.Size([])\n",
      "zpve torch.Size([])\n",
      "U0 torch.Size([])\n",
      "U torch.Size([])\n",
      "H torch.Size([])\n",
      "G torch.Size([])\n",
      "Cv torch.Size([])\n",
      "omega1 torch.Size([])\n",
      "zpve_thermo torch.Size([])\n",
      "U0_thermo torch.Size([])\n",
      "U_thermo torch.Size([])\n",
      "H_thermo torch.Size([])\n",
      "G_thermo torch.Size([])\n",
      "Cv_thermo torch.Size([])\n",
      "one_hot torch.Size([29, 5])\n"
     ]
    }
   ],
   "source": [
    "dataloaders, charge_scale = dataset.retrieve_dataloaders(96, 2)\n",
    "meann, mad = qm9_utils.compute_mean_mad(dataloaders, 'homo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01488416708213051"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(pred*0.4405 -6.5369 - homo).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4405)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.int64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_402629/4152546382.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Add the y=x line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_xlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_xlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.int64' object is not callable"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(pred*0.4405 -6.5369, homo)\n",
    "\n",
    "# Add the y=x line\n",
    "lim = [min(ax.get_xlim() + ax.get_ylim()), max(ax.get_xlim() + ax.get_ylim())]\n",
    "ax.set_xlim(lim)\n",
    "ax.set_ylim(lim)\n",
    "ax.plot(lim, lim, 'k--')\n",
    "\n",
    "# ax.set_xlabel(result_name + ' Label')\n",
    "# ax.set_ylabel('dimenetpp Pred')\n",
    "# name=result_name.split('/')[-1].split('.')[0]\n",
    "# ax.set_title(name)\n",
    "fig.set_size_inches(5 * 4,5)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('megnetclone': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1781827b474c1d75ea45b22315146645a4985aa1c6f5eb176766b21950282489"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
